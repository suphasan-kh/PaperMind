{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9344220464404183,
  "eval_steps": 500,
  "global_step": 11500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12758356723653994,
      "grad_norm": 7.87572717666626,
      "learning_rate": 1.974483286552692e-05,
      "loss": 2.4452,
      "step": 500
    },
    {
      "epoch": 0.25516713447307987,
      "grad_norm": 7.496060848236084,
      "learning_rate": 1.948966573105384e-05,
      "loss": 1.878,
      "step": 1000
    },
    {
      "epoch": 0.3827507017096198,
      "grad_norm": 17.305749893188477,
      "learning_rate": 1.9234498596580763e-05,
      "loss": 1.606,
      "step": 1500
    },
    {
      "epoch": 0.5103342689461597,
      "grad_norm": 12.355045318603516,
      "learning_rate": 1.8979331462107682e-05,
      "loss": 1.506,
      "step": 2000
    },
    {
      "epoch": 0.6379178361826997,
      "grad_norm": 14.055887222290039,
      "learning_rate": 1.87241643276346e-05,
      "loss": 1.3625,
      "step": 2500
    },
    {
      "epoch": 0.7655014034192396,
      "grad_norm": 17.958402633666992,
      "learning_rate": 1.846899719316152e-05,
      "loss": 1.2614,
      "step": 3000
    },
    {
      "epoch": 0.8930849706557795,
      "grad_norm": 12.8121976852417,
      "learning_rate": 1.8213830058688443e-05,
      "loss": 1.2159,
      "step": 3500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1299797296524048,
      "eval_runtime": 13.1116,
      "eval_samples_per_second": 298.895,
      "eval_steps_per_second": 37.371,
      "step": 3919
    },
    {
      "epoch": 1.0206685378923195,
      "grad_norm": 10.576685905456543,
      "learning_rate": 1.7958662924215363e-05,
      "loss": 1.1604,
      "step": 4000
    },
    {
      "epoch": 1.1482521051288594,
      "grad_norm": 15.261366844177246,
      "learning_rate": 1.7703495789742282e-05,
      "loss": 0.9645,
      "step": 4500
    },
    {
      "epoch": 1.2758356723653994,
      "grad_norm": 32.221595764160156,
      "learning_rate": 1.74483286552692e-05,
      "loss": 1.0112,
      "step": 5000
    },
    {
      "epoch": 1.4034192396019392,
      "grad_norm": 10.413118362426758,
      "learning_rate": 1.7193161520796124e-05,
      "loss": 0.9699,
      "step": 5500
    },
    {
      "epoch": 1.5310028068384791,
      "grad_norm": 19.158597946166992,
      "learning_rate": 1.6937994386323043e-05,
      "loss": 0.9941,
      "step": 6000
    },
    {
      "epoch": 1.658586374075019,
      "grad_norm": 7.214492321014404,
      "learning_rate": 1.6682827251849962e-05,
      "loss": 0.928,
      "step": 6500
    },
    {
      "epoch": 1.786169941311559,
      "grad_norm": 16.36038589477539,
      "learning_rate": 1.6427660117376882e-05,
      "loss": 0.95,
      "step": 7000
    },
    {
      "epoch": 1.913753508548099,
      "grad_norm": 13.195213317871094,
      "learning_rate": 1.61724929829038e-05,
      "loss": 0.9152,
      "step": 7500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.9835283756256104,
      "eval_runtime": 13.1113,
      "eval_samples_per_second": 298.902,
      "eval_steps_per_second": 37.372,
      "step": 7838
    },
    {
      "epoch": 2.041337075784639,
      "grad_norm": 10.620834350585938,
      "learning_rate": 1.5917325848430724e-05,
      "loss": 0.8586,
      "step": 8000
    },
    {
      "epoch": 2.168920643021179,
      "grad_norm": 16.6121826171875,
      "learning_rate": 1.5662158713957643e-05,
      "loss": 0.7137,
      "step": 8500
    },
    {
      "epoch": 2.296504210257719,
      "grad_norm": 11.44039249420166,
      "learning_rate": 1.5406991579484562e-05,
      "loss": 0.7209,
      "step": 9000
    },
    {
      "epoch": 2.424087777494259,
      "grad_norm": 22.64487648010254,
      "learning_rate": 1.5151824445011485e-05,
      "loss": 0.7164,
      "step": 9500
    },
    {
      "epoch": 2.551671344730799,
      "grad_norm": 27.063634872436523,
      "learning_rate": 1.4896657310538404e-05,
      "loss": 0.7056,
      "step": 10000
    },
    {
      "epoch": 2.6792549119673383,
      "grad_norm": 9.699446678161621,
      "learning_rate": 1.4641490176065325e-05,
      "loss": 0.7251,
      "step": 10500
    },
    {
      "epoch": 2.8068384792038783,
      "grad_norm": 11.25636100769043,
      "learning_rate": 1.4386323041592244e-05,
      "loss": 0.6971,
      "step": 11000
    },
    {
      "epoch": 2.9344220464404183,
      "grad_norm": 42.84763717651367,
      "learning_rate": 1.4131155907119165e-05,
      "loss": 0.7368,
      "step": 11500
    }
  ],
  "logging_steps": 500,
  "max_steps": 39190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2192434122752e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
